abline(v=x,lwd=3)
# posteriori
tau_linha_2 <- tau0_2 + tau_2
mu_linha <- tau0_2/tau_linha_2*mu0+
tau_2/tau_linha_2*x
lines(grid_mu,dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2)),
type="l",lwd=3,xlab=expression(mu),col=4)
grid_mu <- seq(100,200,length.out = 1000)
library(ggplot2)
# priori para mu (altura média de um brasileiro)
mu0 <- 165
sigma0 <- 10
tau0_2 <- 1/(sigma0)^2
data_plot <- data.frame(grid_mu,
ggplot(data_plot)+
geom_line(aes(x=grid_mu,y=density))
grid_mu <- seq(100,200,length.out = 1000)
library(ggplot2)
# priori para mu (altura média de um brasileiro)
mu0 <- 165
sigma0 <- 10
tau0_2 <- 1/(sigma0)^2
data_plot <- data.frame(grid_mu,
density=dnorm(grid_mu,mu0,sigma0,distribution="prior"))
ggplot(data_plot)+
geom_line(aes(x=grid_mu,y=density))
data_plot <- data.frame(grid_mu,
density=dnorm(grid_mu,mu0,sigma0,distribution="prior"))
# dados (altura medida de um indivíduo - normal com média conhecida)
x <- 180
sigma <- 5
tau_2 <- 1/(sigma)^2
# posteriori
tau_linha_2 <- tau0_2 + tau_2
mu_linha <- tau0_2/tau_linha_2*mu0+
tau_2/tau_linha_2*x
data_plot <- rbind(data_plot,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2),
data_plot <- rbind(data_plot,
data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2),
distribution="posterior")))
grid_mu <- seq(100,200,length.out = 1000)
library(ggplot2)
# priori para mu (altura média de um brasileiro)
mu0 <- 165
sigma0 <- 10
tau0_2 <- 1/(sigma0)^2
data_plot <- data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu0,sigma0),
distribution="prior")
ggplot(data_plot)+
geom_line(aes(x=mu,y=density))
# dados (altura medida de um indivíduo - normal com média conhecida)
x <- 180
sigma <- 5
tau_2 <- 1/(sigma)^2
# posteriori
tau_linha_2 <- tau0_2 + tau_2
mu_linha <- tau0_2/tau_linha_2*mu0+
tau_2/tau_linha_2*x
data_plot <- rbind(data_plot,
data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2),
distribution="posterior")))
data_plot <- rbind(data_plot,
data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2)),
distribution="posterior"))
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution))
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=2)
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=2)+
theme_minimal()
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=2)+
theme_minimal(base_size = 14)
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=2)+
theme_minimal(base_size = 14)+xlab(expression(mu))+xlab("Density")
mu_linha
tau_linha_2
grid_mu <- seq(100,200,length.out = 1000)
library(ggplot2)
# priori para mu (altura média de um brasileiro)
mu0 <- 165
sigma0 <- 100
tau0_2 <- 1/(sigma0)^2
data_plot <- data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu0,sigma0),
distribution="prior")
ggplot(data_plot)+
geom_line(aes(x=mu,y=density))
# dados (altura medida de um indivíduo - normal com média conhecida)
x <- 180
sigma <- 5
tau_2 <- 1/(sigma)^2
# posteriori
tau_linha_2 <- tau0_2 + tau_2
mu_linha <- tau0_2/tau_linha_2*mu0+
tau_2/tau_linha_2*x
data_plot <- rbind(data_plot,
data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2)),
distribution="posterior"))
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=2)+
theme_minimal(base_size = 14)+xlab(expression(mu))+ylab("Density")
grid_mu <- seq(100,200,length.out = 1000)
library(ggplot2)
# priori para mu (altura média de um brasileiro)
mu0 <- 165
sigma0 <- 20
tau0_2 <- 1/(sigma0)^2
data_plot <- data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu0,sigma0),
distribution="prior")
ggplot(data_plot)+
geom_line(aes(x=mu,y=density))
# dados (altura medida de um indivíduo - normal com média conhecida)
x <- 180
sigma <- 5
tau_2 <- 1/(sigma)^2
# posteriori
tau_linha_2 <- tau0_2 + tau_2
mu_linha <- tau0_2/tau_linha_2*mu0+
tau_2/tau_linha_2*x
data_plot <- rbind(data_plot,
data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2)),
distribution="posterior"))
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=2)+
theme_minimal(base_size = 14)+xlab(expression(mu))+ylab("Density")
library(ggplot2)
grid_mu <- seq(100,200,length.out = 1000)
# priori para mu (altura média de um brasileiro)
mu0 <- 165
sigma0 <- 10
tau0_2 <- 1/(sigma0)^2
data_plot <- data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu0,sigma0),
distribution="priori")
# dados (altura medida de um indivíduo - normal com média conhecida)
x <- 180
sigma <- 5
tau_2 <- 1/(sigma)^2
# posteriori
tau_linha_2 <- tau0_2 + tau_2
mu_linha <- tau0_2/tau_linha_2*mu0+
tau_2/tau_linha_2*x
data_plot <- rbind(data_plot,
data.frame(mu=grid_mu,
density=dnorm(grid_mu,mu_linha,1/sqrt(tau_linha_2)),
distribution="posteriori"))
ggplot(data_plot)+
geom_line(aes(x=mu,y=density,color=distribution),size=1.2)+
theme_minimal(base_size = 14)+xlab(expression(mu))+ylab("Densidade")+
theme(legend.title=element_blank())
# X ~ N(mu,sigma)
sigma <- 7.5
mu <- 170
alturas <- rnorm(100,mu,sigma)
hist(alturas)
# Frequentista, EMV
mean(alturas)
#  Bayesiano
mu0 <- 165
lambda <- 1
grid_tau <- seq(0,0.1,length.out = 10000)
beta <- 1
alpha <- 0.1*beta
hist(rgamma(1000,
alpha,beta))
plot(grid_tau,dgamma(grid_tau,
alpha,beta))
hist(rgamma(1000,
alpha,beta))
plot(grid_tau,dgamma(grid_tau,
alpha,beta))
grid_tau <- seq(0,0.01,length.out = 10000)
beta <- 1
alpha <- 0.1*beta
plot(grid_tau,dgamma(grid_tau,
alpha,beta))
?dgamma
# X ~ N(mu,sigma)
sigma <- 0.75
mu <- 1.70
alturas <- rnorm(100,mu,sigma)
hist(alturas)
grid_tau <- seq(0,0.01,
length.out = 10000)
beta <- 1
alpha <- 100*beta
plot(grid_tau,dgamma(grid_tau,
alpha,beta))
grid_tau <- seq(0,300,
length.out = 10000)
beta <- 1
alpha <- 100*beta
plot(grid_tau,dgamma(grid_tau,
alpha,beta))
library(FNN)
library(fields)
library(nnet)
library(gmodels)
library(randomForest)
# Gera dados
nTrain=2000
library(FNN)
library(fields)
library(nnet)
library(gmodels)
install.packages("gmodels")
library(gmodels)
library(randomForest)
# Gera dados
nTrain=2000
nTrain0=4000
n=nTrain+nTrain0
d=1
data=matrix(NA,n,d+1)
data[,1:d]=matrix(rnorm(n*d,0,1),n,d)
#Número de categorias resposta-1
p=4
#Betas
beta=matrix(NA,nrow=p,ncol=1)
set.seed(3)
beta = rnorm(p,0,5)
#Função variável resposta
resp = function(x,p){
Denominator=1
for(i in 1:p){Denominator=Denominator+exp(beta[i]*x)}
vProb = cbind(1/Denominator,exp(x*beta[1])/Denominator)
if (p>1) {for(i in 2:p){vProb = cbind(vProb,exp(x*beta[i])/Denominator)}}
mChoices = t(apply(vProb, 1, rmultinom, n = 1, size = 1))#gera multinomial
return(apply(mChoices, 1, function(x) which(x==1)))
}
#Função Qtd diferente para resumo
qtd_dif=function(x){length(unique(x))}
data[,d+1]=resp(x=data[,1:d],p=p)
table(data[,d+1])
plot(data[,1],data[,d+1],pch=20,xlim=c(-5,5),xlab="X",ylab="Y")
plot(table(data[,d+1]),xlab="y",ylab="Frequência")
randomIndex=sample(1:n)
xTrain=data[randomIndex[1:nTrain],1:d]
xTrain0=data[randomIndex[(nTrain+1):n],1:d]
yTrain=data[randomIndex[1:nTrain],d+1]
yTrain0=data[randomIndex[(nTrain+1):n],d+1]
#Função distribuição probabilidade
dens = function(x,y){
Denominator=1
for(i in 1:p){Denominator=Denominator+exp(beta[i]*x)}
vProb = cbind(1/Denominator,exp(x*beta[1])/Denominator)
if (p>1) {for(i in 2:p){vProb = cbind(vProb,exp(x*beta[i])/Denominator)}}
return(c(vProb[y]))
}
fit<-(multinom(yTrain0 ~ xTrain0, cbind.data.frame(yTrain0,xTrain0)))
predictedValues=predict(fit, newdata = data.frame(xTrain0=xTrain),type = "probs")
predictedValues[1:5,]
fit<-randomForest(y=as.factor(yTrain0),x=as.matrix(xTrain0))
predictedValues=predict(fit, x=as.matrix(xTrain),type = "prob")
predictedValues[1:5,]
knn.indice = function(xTrain,xTest,k){
n.test = nrow(as.matrix(xTest))
viz.test = matrix(0, nrow = n.test, ncol = k)
dist.train = rdist(xTest,xTrain)
for(i in 1:n.test){
dist = dist.train[i,]
viz.test[i,] = order(dist)[1:(k)]
}
return(viz.test)
}
cplocaldist = function(k,alfa){
#Variável explicativa
data[,1:d]=matrix(rnorm(n*d,0,1),n,d)
# Variável resposta
data[,d+1]=resp(x=data[,1:d],p=p)
# split data (sem index)
xTrain=data[randomIndex[1:nTrain],1:d]
yTrain=data[randomIndex[1:nTrain],d+1]
#Densidade estimada para novo xTrain
#pred_xTrain=predict(fit, newdata = data.frame(xTrain0=xTrain),type = "probs")
pred_xTrain=predict(fit, x=as.matrix(xTrain),type = "prob")
#grid y
y_grid=c(1:(p+1))
#grid x
xTest_grid=seq(-4,4, length.out = 2000)
#Gera y corresponde ao x grid
yTest_grid=resp(x=xTest_grid,p=p)
#Densidade estimada para xTest_grid
#pred_xTest_grid=predict(fit, newdata = data.frame(xTrain0=xTest_grid),type = "probs")
pred_xTest_grid=predict(fit, x=as.matrix(xTest_grid),type = "prob")
#g train e g test
#t_grid=seq(0,1,length.out = 500)
#gx_train=matrix(NA, nrow = nrow(as.matrix(xTrain)), ncol=length(t_grid))
#gx_test=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=length(t_grid))
gx_train=matrix(NA, nrow = nrow(as.matrix(xTrain)), ncol=p+1)
gx_test=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=p+1)
#for(i in 1:nrow(as.matrix(xTest_grid))){gx_test[i,]=g(t_grid,y_grid,pred_xTest_grid[i,] )}  #estimativa f para XText_grid
#for(i in 1:nrow(as.matrix(xTrain))){gx_train[i,]=g(t_grid,y_grid,pred_xTrain[i,] )}  #usa estimativa f para xTrain
for(i in 1:nrow(as.matrix(xTest_grid))){gx_test[i,]=pred_xTest_grid[i,]}  #estimativa f para XText_grid
for(i in 1:nrow(as.matrix(xTrain))){gx_train[i,]=pred_xTrain[i,]}  #usa estimativa f para xTrain
#elementos do treino próximos de cada teste
x_test_viz=knn.indice(gx_train,gx_test,k)
#percentil 1-alfa para cada teste
mat_cde_kviz=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=k)
p_alfa=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=1)
for(i in 1:nrow(as.matrix(xTest_grid))){
for(j in 1:k){mat_cde_kviz[i,j]=pred_xTrain[x_test_viz[i,j],yTrain[x_test_viz[i,j]]]}} #estimativa f
for(i in 1:nrow(as.matrix(xTest_grid))){p_alfa[i]=quantile(mat_cde_kviz[i,],prob=alfa)}
#indicador de cobertura e comprimento
Ind=matrix(NA, nrow = length(xTest_grid))
xTestBand = matrix(0, nrow = length(xTest_grid), ncol=p+1)
Comp=matrix(NA, nrow = nrow(as.matrix(xTest_grid)))
for(i in 1:length(xTest_grid)){
xTestBand[i,]=ifelse(pred_xTest_grid[i,]>=p_alfa[i],y_grid,NA) #estimativa f
Ind[i]=ifelse(pred_xTest_grid[i,yTest_grid[i]]>=p_alfa[i],1,0) #estimativa f
Comp[i]=sum(abs(diff(xTestBand[i,])),na.rm=TRUE)
}
return(list(Ind,Comp,xTestBand))
}
bandapred=cplocaldist(k=100,alfa = 0.1)
mean(bandapred[[1]])
mean(bandapred[[2]])
bandapred[[1]]
hist(bandapred[[1]])
hist((bandapred[[2]])
)
library(FNN)
library(fields)
library(nnet)
library(gmodels)
library(randomForest)
# Gera dados
nTrain=2000
nTrain0=4000
n=nTrain+nTrain0
d=1
data=matrix(NA,n,d+1)
data[,1:d]=matrix(rnorm(n*d,0,1),n,d)
#Número de categorias resposta-1
p=4
#Betas
beta=matrix(NA,nrow=p,ncol=1)
set.seed(3)
beta = rnorm(p,0,5)
#Função variável resposta
resp = function(x,p){
Denominator=1
for(i in 1:p){Denominator=Denominator+exp(beta[i]*x)}
vProb = cbind(1/Denominator,exp(x*beta[1])/Denominator)
if (p>1) {for(i in 2:p){vProb = cbind(vProb,exp(x*beta[i])/Denominator)}}
mChoices = t(apply(vProb, 1, rmultinom, n = 1, size = 1))#gera multinomial
return(apply(mChoices, 1, function(x) which(x==1)))
}
#Função Qtd diferente para resumo
qtd_dif=function(x){length(unique(x))}
data[,d+1]=resp(x=data[,1:d],p=p)
table(data[,d+1])
plot(data[,1],data[,d+1],pch=20,xlim=c(-5,5),xlab="X",ylab="Y")
plot(table(data[,d+1]),xlab="y",ylab="Frequência")
randomIndex=sample(1:n)
xTrain=data[randomIndex[1:nTrain],1:d]
xTrain0=data[randomIndex[(nTrain+1):n],1:d]
yTrain=data[randomIndex[1:nTrain],d+1]
yTrain0=data[randomIndex[(nTrain+1):n],d+1]
#Função distribuição probabilidade
dens = function(x,y){
Denominator=1
for(i in 1:p){Denominator=Denominator+exp(beta[i]*x)}
vProb = cbind(1/Denominator,exp(x*beta[1])/Denominator)
if (p>1) {for(i in 2:p){vProb = cbind(vProb,exp(x*beta[i])/Denominator)}}
return(c(vProb[y]))
}
fit<-(multinom(yTrain0 ~ xTrain0, cbind.data.frame(yTrain0,xTrain0)))
predictedValues=predict(fit, newdata = data.frame(xTrain0=xTrain),type = "probs")
predictedValues[1:5,]
fit<-randomForest(y=as.factor(yTrain0),x=as.matrix(xTrain0))
predictedValues=predict(fit, x=as.matrix(xTrain),type = "prob")
predictedValues[1:5,]
knn.indice = function(xTrain,xTest,k){
n.test = nrow(as.matrix(xTest))
viz.test = matrix(0, nrow = n.test, ncol = k)
dist.train = rdist(xTest,xTrain)
for(i in 1:n.test){
dist = dist.train[i,]
viz.test[i,] = order(dist)[1:(k)]
}
return(viz.test)
}
cplocaldist = function(k,alfa){
#Variável explicativa
data[,1:d]=matrix(rnorm(n*d,0,1),n,d)
# Variável resposta
data[,d+1]=resp(x=data[,1:d],p=p)
# split data (sem index)
xTrain=data[randomIndex[1:nTrain],1:d]
yTrain=data[randomIndex[1:nTrain],d+1]
#Densidade estimada para novo xTrain
#pred_xTrain=predict(fit, newdata = data.frame(xTrain0=xTrain),type = "probs")
pred_xTrain=predict(fit, x=as.matrix(xTrain),type = "prob")
#grid y
y_grid=c(1:(p+1))
#grid x
xTest_grid=seq(-4,4, length.out = 2000)
#Gera y corresponde ao x grid
yTest_grid=resp(x=xTest_grid,p=p)
#Densidade estimada para xTest_grid
#pred_xTest_grid=predict(fit, newdata = data.frame(xTrain0=xTest_grid),type = "probs")
pred_xTest_grid=predict(fit, x=as.matrix(xTest_grid),type = "prob")
#g train e g test
#t_grid=seq(0,1,length.out = 500)
#gx_train=matrix(NA, nrow = nrow(as.matrix(xTrain)), ncol=length(t_grid))
#gx_test=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=length(t_grid))
gx_train=matrix(NA, nrow = nrow(as.matrix(xTrain)), ncol=p+1)
gx_test=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=p+1)
#for(i in 1:nrow(as.matrix(xTest_grid))){gx_test[i,]=g(t_grid,y_grid,pred_xTest_grid[i,] )}  #estimativa f para XText_grid
#for(i in 1:nrow(as.matrix(xTrain))){gx_train[i,]=g(t_grid,y_grid,pred_xTrain[i,] )}  #usa estimativa f para xTrain
for(i in 1:nrow(as.matrix(xTest_grid))){gx_test[i,]=pred_xTest_grid[i,]}  #estimativa f para XText_grid
for(i in 1:nrow(as.matrix(xTrain))){gx_train[i,]=pred_xTrain[i,]}  #usa estimativa f para xTrain
#elementos do treino próximos de cada teste
x_test_viz=knn.indice(gx_train,gx_test,k)
#percentil 1-alfa para cada teste
mat_cde_kviz=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=k)
p_alfa=matrix(NA, nrow = nrow(as.matrix(xTest_grid)), ncol=1)
for(i in 1:nrow(as.matrix(xTest_grid))){
for(j in 1:k){mat_cde_kviz[i,j]=pred_xTrain[x_test_viz[i,j],yTrain[x_test_viz[i,j]]]}} #estimativa f
for(i in 1:nrow(as.matrix(xTest_grid))){p_alfa[i]=quantile(mat_cde_kviz[i,],prob=alfa)}
#indicador de cobertura e comprimento
Ind=matrix(NA, nrow = length(xTest_grid))
xTestBand = matrix(0, nrow = length(xTest_grid), ncol=p+1)
Comp=matrix(NA, nrow = nrow(as.matrix(xTest_grid)))
for(i in 1:length(xTest_grid)){
xTestBand[i,]=ifelse(pred_xTest_grid[i,]>=p_alfa[i],y_grid,NA) #estimativa f
Ind[i]=ifelse(pred_xTest_grid[i,yTest_grid[i]]>=p_alfa[i],1,0) #estimativa f
Comp[i]=sum(abs(diff(xTestBand[i,])),na.rm=TRUE)
}
return(list(Ind,Comp,xTestBand))
}
bandapred=cplocaldist(k=100,alfa = 0.1)
mean(bandapred[[1]])
mean(bandapred[[2]])
predictedValues
predictedValues[1:5,]
predictedValues[1:5,]
xTrain[1]
?randomForest
fit1<-randomForest(y=as.numeric(yTrain0==1),
x=as.matrix(xTrain0))
predictedValues1=predict(fit1, x=as.matrix(xTrain))
predictedValues1
predictedValues1[1]
xTrain[1]
fit2<-randomForest(y=as.numeric(yTrain0==2),
x=as.matrix(xTrain0))
predictedValues1=predict(fit2, x=as.matrix(xTrain))
predictedValues1[1]
predictedValues1=predict(fit1, x=as.matrix(xTrain))
predictedValues2=predict(fit2, x=as.matrix(xTrain))
predictedValues1[1]
predictedValues2[1]
predictedValues[1,]
fit5<-randomForest(y=as.numeric(yTrain0==5),
x=as.matrix(xTrain0))
predictedValues5=predict(fit5, x=as.matrix(xTrain))
predictedValues5[1]
rbind(predictedValues1,predictedValues2,predictedValues5)[1:5,]
cbind(predictedValues1,predictedValues2,predictedValues5)[1:5,]
predictedValues[1:5,]
xTrain[5]
mean(bandapred[[2]])
bandapred[[2]]
table(bandapred[[2]])
predictedValues[1:5,]
d <- seq(0,1,length.out = 1000)
d <- seq(0,1,length.out = 1000)
plot(d,dbeta(d,5,5),type="l",lwd=3,xlab=expression(theta))
plot(d,dbeta(d,5,5),type="l",lwd=3,xlab=expression(theta),ylab="Densidade")
plot(d,dbeta(d,5,5),type="l",lwd=3,xlab=expression(theta),ylab="Densidade",cex.lab=1.3)
x=10
n=30
lines(d,dbeta(d,5+x,5+n-x),col=2,lwd=3)
plot(d,dbeta(d,5,5),type="l",lwd=3,xlab=expression(theta),ylab="Densidade",
cex.lab=1.3,col=4,ylim=c(0,4))
x=10
n=15
lines(d,dbeta(d,5+x,5+n-x),col=2,lwd=3)
1-pbeta(0.5,25,15)
setwd("/mnt/62e7a18d-9e67-46b5-8b12-bcb7dc0301ab/Dropbox/Izbicki/Research/UFSCar/Gilson/conformal-cde-experiments")
source("requirements.R")
source("base_functions.R")
data_plot <- read_all_rds("rds/gamma/")
plot_perfomance_n_paper(data_plot,title = "Asymmetric",folder = "gamma/")
data_plot <- read_all_rds("rds/gamma_v2/")
plot_perfomance_n_paper(data_plot,title = "Asymmetric",folder = "gamma2/")
data_plot <- read_all_rds("rds/gaussian_het/")
plot_perfomance_n_paper(data_plot,title = "Heteroscedastic",folder = "gaussian_het/")
data_plot <- read_all_rds("rds/gaussian_hom/")
plot_perfomance_n_paper(data_plot,title = "Homoscedastic",folder = "gaussian_hom/")
data_plot <- read_all_rds("rds/bimodal/")
plot_perfomance_n_paper(data_plot,title = "Bimodal",folder = "bimodal/")
data_plot <- read_all_rds("rds/quantile/")
plot_perfomance_n_paper(data_plot,title = "Quantile",folder = "quantile/")
data_plot <- read_all_rds("rds/gamma_v2/")
data_plot
plot_perfomance_n_paper(data_plot,title = "Asymmetric",folder = "gamma2/")
data_plot <- read_all_rds("rds/gaussian_het/")
data_plot
